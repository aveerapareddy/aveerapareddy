## Hi, I'm Akhilesh

**AI/ML Engineer | Full Stack Engineer (Python, Angular, Java) | MLOps & Cloud**

I build intelligent, scalable systems combining **Machine Learning, LLMs, Deep Learning, RAG architectures, Vector Search, and end-to-end software engineering**.  
With 10+ years of full-stack engineering and cloud experience, I‚Äôm transitioning into a full-time **AI/ML Engineering** role through hands-on, production-grade AI projects.

‚öôÔ∏è Core Skills: **PyTorch ‚Ä¢ Transformers ‚Ä¢ LLM Fine-Tuning (QLoRA) ‚Ä¢ RAG ‚Ä¢ Vector Databases ‚Ä¢ MLFlow ‚Ä¢ FastAPI ‚Ä¢ Docker ‚Ä¢ Databricks ‚Ä¢ Azure/GCP**  
üéì Completed Stanford **AI & Machine Learning Professional Program**

---

## üöÄ My AI/ML Projects (In Progress ‚Äì Production-Ready)

The following **5 major projects** represent the full spectrum of AI/ML engineering‚Äî  
LLM fine-tuning ‚Üí retrieval systems ‚Üí deep learning ‚Üí classical ML ‚Üí MLOps + deployment.

---

### üîπ **1. llm-finetuner-qlora**  
**Domain-Specific LLM Fine-Tuning using QLoRA (Llama/Mistral models)**  
Building a memory-efficient LLM fine-tuning system using **4-bit quantization and PEFT adapters**.  
Includes dataset processing, training/evaluation pipelines, and **FastAPI GPU inference server**, with the final model published on HuggingFace.

**Tech:** PyTorch, Transformers, QLoRA, PEFT, Tokenizers, FastAPI, GPUs

---

### üîπ **2. enterprise-rag-engine**  
**End-to-End RAG (Retrieval-Augmented Generation) System with Vector Search**  
Full retrieval pipeline including **document ingestion, embeddings, FAISS indexing, top-k retrieval, metadata filtering, and re-ranking**.  
Integrated with an LLM for high-accuracy enterprise Q&A, plus evaluation metrics for retrieval and answer quality.

**Tech:** FAISS, Chroma, Embeddings, Transformers, RAG, Re-Ranking, FastAPI

---

### üîπ **3. pytorch-deeplearning-models**  
**Custom Deep Learning Models (CNN / LSTM / Transformer) Implemented from Scratch**  
Building deep learning architectures using **pure PyTorch**, including training loops, datasets, optimizers, checkpointing, and GPU acceleration.  
Focus areas: image classification, time-series forecasting, and text modeling.

**Tech:** PyTorch, CNNs, LSTMs, Transformers, Dataloaders, GPU Training

---

### üîπ **4. mlops-pipeline-e2e**  
**End-to-End MLOps Pipeline: Training ‚Üí Registry ‚Üí Deployment ‚Üí Monitoring**  
A complete ML operations workflow using **MLflow + Docker + CI/CD + Cloud deployment**.  
Supports training orchestration, model versioning, API serving, automated updates, and drift/latency monitoring dashboards.

**Tech:** MLFlow, Docker, GitHub Actions, FastAPI, Azure/GCP, Feature Engineering

---

### üîπ **5. classical-ml-system**  
**Real-World Predictive ML System (Churn / Fraud / Credit Risk)**  
A full classical ML pipeline focusing on **data cleaning, feature engineering, model benchmarking, hyperparameter tuning, and SHAP explainability**.  
Demonstrates mastery of foundational ML required in all interviews.

**Tech:** Scikit-Learn, XGBoost, Pandas, SHAP, Metrics, Feature Engineering

---

## üåê Connect with Me

- **LinkedIn:** https://linkedin.com/in/aveerapareddy  
- **Portfolio:** https://akhilesh.dev  

---

‚ö° I push code daily ‚Äî follow along as I build these production-ready LLM, RAG, Deep Learning, and MLOps systems and transition into full-time **AI/ML Engineering**.
